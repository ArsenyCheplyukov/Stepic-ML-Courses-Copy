 # Генерация цитат различных общественных личностей (на англ.яз.) и коротких предложений "Войны и мир" на рус.яз. 
 ### Стэк: Pytorch (RNN, GRU, LSTM)
 ### *Вычисления проводились на Google Colab*

В ноутбуке рассмотрены способы организации обучения RNN, GRU, LSTM моделей для целей прогнозирования следующего символа на основании предшествующих. 

Обучение моделей проводится на датасетах, предоставленных командой курса Samsung, а именно "Quotes" и "Война и мир"

RNN в ноутбуке реализовано в двух способах:
* хэнд-мэйд RNN
* RNN из пакета Pytorch

После обучения моделей мы сгенерируем несколько предложений и посмотрим как модель научилась предсказывать символы, оценим насколько близко наша модель к естественному языку

Основная задача - понять механику RNN и научиться использовать реккурентные сети в задачах NLP

В целях компактности исследования, на каждом датасете мы обучим только по одной LSTM модели. Проводить сравнение качества RNN с GRU и LSTM в этом ноутбуке мы не будем.

*По мотивам [семинара](https://github.com/Samsung-IT-Academy/stepik-dl-nlp/blob/master/task4_RNN_name_generator.ipynb)
 курса ["Нейронные сети и обработка текста (Samsung)"](https://stepik.org/lesson/262247/step/1?unit=243130)*
 
 ##### Внимание!!! 
 ##### Файл с параметрами обученной модели на датасете "Война и мир" > 32мб и поэтому не копируется на гит
