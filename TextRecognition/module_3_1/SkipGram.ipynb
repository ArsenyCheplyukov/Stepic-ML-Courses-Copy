{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd020dfe1c3a30423f91dbe21abc93c47f1ad7995f768354707f3e327398f9ce3c3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def init_random_seed(value=0):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#import dlnlputils\n",
    "#from dlnlputils.data import tokenize_corpus, build_vocabulary, texts_to_token_ids, \\\n",
    "#    PaddedSequenceDataset, Embeddings\n",
    "#from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "#from dlnlputils.visualization import plot_vectors\n",
    "\n",
    "init_random_seed()"
   ]
  },
  {
   "source": [
    "## Алгоритм обучения - Skip Gram Negative Sampling\n",
    "\n",
    "**Skip Gram** - предсказываем соседние слова по центральному слову\n",
    "\n",
    "**Negative Sampling** - аппроксимация softmax\n",
    "\n",
    "$$ W, D \\in \\mathbb{R}^{Vocab \\times EmbSize} $$\n",
    "\n",
    "$$ \\sum_{CenterW_i} P(CtxW_{-2}, CtxW_{-1}, CtxW_{+1}, CtxW_{+2} | CenterW_i; W, D) \\rightarrow \\max_{W,D} $$\n",
    "\n",
    "$$ P(CtxW_{-2}, CtxW_{-1}, CtxW_{+1}, CtxW_{+2} | CenterW_i; W, D) = \\prod_j P(CtxW_j | CenterW_i; W, D) $$\n",
    "    \n",
    "$$ P(CtxW_j | CenterW_i; W, D) = \\frac{e^{w_i \\cdot d_j}} { \\sum_{j=1}^{|V|} e^{w_i \\cdot d_j}} = softmax \\simeq \\frac{e^{w_i \\cdot d_j^+}} { \\sum_{j=1}^{k} e^{w_i \\cdot d_j^-}}, \\quad k \\ll |V| $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "def make_diag_mask(size, radius):\n",
    "    \"\"\"Квадратная матрица размера Size x Size с двумя полосами ширины radius вдоль главной диагонали\"\"\"\n",
    "    #idxs = torch.arange(size)\n",
    "    #abs_idx_diff = (idxs.unsqueeze(0) - idxs.unsqueeze(1)).abs()\n",
    "    #mask = ((abs_idx_diff <= radius) & (abs_idx_diff > 0)).float()\n",
    "    mask = np.ones((size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(size): \n",
    "            if ((i == j) | (i - j > radius) | (j - i > radius)):\n",
    "                mask[i, j] = 0\n",
    "    return mask\n",
    "\n",
    "make_diag_mask(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(text, matrix, state):\n",
    "    lst = []\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if (matrix[i, j] == state):\n",
    "                lst_1 = []\n",
    "                lst_1.append(text[i])\n",
    "                lst_1.append(text[j])\n",
    "                lst_1.append(state)\n",
    "                lst.append(lst_1)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [1, 0, 1, 0, 0, 5, 0, 3, 5, 5, 3, 0, 5, 0, 5, 2, 0, 1, 3]\n",
    "window_size = 3\n",
    "ns_rate = 1\n",
    "voc = 6\n",
    "\n",
    "generated_text = [x for x in range(voc)]\n",
    "\n",
    "matrix = make_diag_mask(len(text), (window_size // 2))\n",
    "pos_list_exist = np.array(find_index(text, matrix, 1))\n",
    "neg_list_exist = np.array(find_index(text, matrix, 0))\n",
    "\n",
    "neg_list_generate = np.array(find_index(generated_text, make_diag_mask(len(generated_text), window_size // 2), 0))\n",
    "\n",
    "if len(neg_list_exist) >= len(pos_list_exist)*ns_rate:\n",
    "    ans = np.concatenate((pos_list_exist, neg_list_exist[:ns_rate*len(pos_list_exist), :]))\n",
    "else:\n",
    "    neg_list_exist = np.concatenate(neg_list_generate, neg_list_exist)\n",
    "    ans = np.concatenate((pos_list_exist, neg_list_exist[:ns_rate*len(pos_list_exist), :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 3, 0],\n",
       "       [0, 4, 0],\n",
       "       [0, 5, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 3, 0],\n",
       "       [1, 4, 0],\n",
       "       [1, 5, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 2, 0],\n",
       "       [2, 4, 0],\n",
       "       [2, 5, 0],\n",
       "       [3, 0, 0],\n",
       "       [3, 1, 0],\n",
       "       [3, 3, 0],\n",
       "       [3, 5, 0],\n",
       "       [4, 0, 0],\n",
       "       [4, 1, 0],\n",
       "       [4, 2, 0],\n",
       "       [4, 4, 0],\n",
       "       [5, 0, 0],\n",
       "       [5, 1, 0],\n",
       "       [5, 2, 0],\n",
       "       [5, 3, 0],\n",
       "       [5, 5, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "neg_list_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36\n325\n72\n"
     ]
    }
   ],
   "source": [
    "print(len(fs_pos_list))\n",
    "print(len(fs_neg_list))\n",
    "print(len(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 5, 1],\n",
       "       [5, 0, 1],\n",
       "       [5, 0, 1],\n",
       "       [0, 5, 1],\n",
       "       [0, 3, 1],\n",
       "       [3, 0, 1],\n",
       "       [3, 5, 1],\n",
       "       [5, 3, 1],\n",
       "       [5, 5, 1],\n",
       "       [5, 5, 1],\n",
       "       [5, 3, 1],\n",
       "       [3, 5, 1],\n",
       "       [3, 0, 1],\n",
       "       [0, 3, 1],\n",
       "       [0, 5, 1],\n",
       "       [5, 0, 1],\n",
       "       [5, 0, 1],\n",
       "       [0, 5, 1],\n",
       "       [0, 5, 1],\n",
       "       [5, 0, 1],\n",
       "       [5, 2, 1],\n",
       "       [2, 5, 1],\n",
       "       [2, 0, 1],\n",
       "       [0, 2, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 3, 1],\n",
       "       [3, 1, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 5, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 3, 0],\n",
       "       [1, 5, 0],\n",
       "       [1, 5, 0],\n",
       "       [1, 3, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 5, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 5, 0],\n",
       "       [1, 2, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 3, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 3, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 3, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 3, 0],\n",
       "       [1, 1, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}